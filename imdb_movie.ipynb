{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Author: Shashi Bala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of contents</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#about_dataset\">About the dataset</a></li>\n",
    "        <li><a href=\"#exploring_the_data\">Data Exploration</a></li>\n",
    "        <li><a href=\"#cleaning_the_data\">Data Cleaning</a></li>\n",
    "        <li><a href=\"#transforming_the_data\">Data Transformation</a></li>\n",
    "        <li><a href=\"#using_parameteric_and_non_parametric_models\">Modeling</a></li>\n",
    "        <li><a href=\"#recommendations\">Recommendation</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Following Libraries:\n",
    "<ul>\n",
    "    <li> <b>numpy (as np)</b> </li>\n",
    "    <li> <b>pandas (as pd)</b> </li>\n",
    "    <li> <b>pandas_profiling</b> </li>\n",
    "    <li> <b>matplotlib.pyplot (as plt)</b> </li>\n",
    "    <li> <b>seaborn (as sns)</b> </li> \n",
    "    <li> <b>warnings</b> </li> \n",
    "    <li> <b>os</b> </li>\n",
    "    <li> <b>series, DataFrame</b> from <b>pandas</b> </li>\n",
    "    <li> <b>stats</b> from <b>scipy.stats</b> </li>\n",
    "    <li> <b>train_test_split</b> from <b>sklearn.model_selection</b> </li>\n",
    "    <li> <b>LinearRegression</b> from <b>sklearn.linear_model</b> </li>\n",
    "    <li> <b>r2_score</b> from <b>sklearn.metrics</b> </li>\n",
    "    <li> <b>statsmodels.api (as sm)</b> </li>\n",
    "    <li> <b>KNeighborsRegressor</b> from <b>sklearn.neighbors</b> </li>\n",
    "    <li> <b>mean_squared_error</b> from <b>sklearn.metrics</b> </li>\n",
    "    <li> <b>neighbors</b> from <b>sklearn</b> </li>\n",
    "    <li> <b>sqrt</b> from <b>math</b> </li>\n",
    "    <li> <b>RandomForestRegressor</b> from <b>sklearn.ensemble</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandas_profiling\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"about_dataset\">\n",
    "    <h2>1. About the dataset</h2>\n",
    "    The dataset is imdb_data_v2 which is in csv file. It contains 38 variables for 5787 movies, spanning across more than 100 years in 65 countries. There are 2399 unique director names, and thousands of actors/actresses. “imdb_score” is the traget/response variable while the other 37 variables are possible predictors.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"exploring_the_data\">\n",
    "     <h2>2. Data Exploration</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>2.1. Data Load</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist imdb_data_v2.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"C:\\Data Science_Interview\\Dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We read in the data we've saved, passing the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\Data Science_Interview\\Dataset\\Data Scientist imdb_data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (5787, 38)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's check out the first few rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_market_idx</th>\n",
       "      <th>days_since_last_tweet</th>\n",
       "      <th>pre_screen_viewers</th>\n",
       "      <th>characters_per_longest_review</th>\n",
       "      <th>priority</th>\n",
       "      <th>longest_facebook_comment_review_char</th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>website_score</th>\n",
       "      <th>budget</th>\n",
       "      <th>weighted_budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>1181</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.9</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>236999000</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1117</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>1196</td>\n",
       "      <td>4</td>\n",
       "      <td>740</td>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.1</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>299999000</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>1125</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.8</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>244999000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1127</td>\n",
       "      <td>4</td>\n",
       "      <td>1074</td>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1128</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1072</td>\n",
       "      <td>4</td>\n",
       "      <td>813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  stock_market_idx  days_since_last_tweet  pre_screen_viewers  \\\n",
       "0   1              1102                     67                  18   \n",
       "1   2              1117                     70                  18   \n",
       "2   3              1000                     90                  11   \n",
       "3   4              1007                     35                  10   \n",
       "4   5              1128                     85                  20   \n",
       "\n",
       "   characters_per_longest_review  priority  \\\n",
       "0                           1181         4   \n",
       "1                           1196         4   \n",
       "2                           1125         4   \n",
       "3                           1127         4   \n",
       "4                           1072         4   \n",
       "\n",
       "   longest_facebook_comment_review_char  color      director_name  \\\n",
       "0                                   250  Color      James Cameron   \n",
       "1                                   740  Color     Gore Verbinski   \n",
       "2                                  1779  Color         Sam Mendes   \n",
       "3                                  1074  Color  Christopher Nolan   \n",
       "4                                   813    NaN        Doug Walker   \n",
       "\n",
       "   num_critic_for_reviews     ...      country  content_rating  website_score  \\\n",
       "0                   723.0     ...          USA           PG-13            7.9   \n",
       "1                   302.0     ...          USA           PG-13            7.1   \n",
       "2                   602.0     ...           UK           PG-13            6.8   \n",
       "3                   813.0     ...          USA           PG-13            8.5   \n",
       "4                     NaN     ...          NaN             NaN            7.1   \n",
       "\n",
       "        budget  weighted_budget  title_year actor_2_facebook_likes  \\\n",
       "0  237000000.0        236999000      2009.0                  936.0   \n",
       "1  300000000.0        299999000      2007.0                 5000.0   \n",
       "2  245000000.0        244999000      2015.0                  393.0   \n",
       "3  250000000.0        249999000      2012.0                23000.0   \n",
       "4          NaN            -1000         NaN                   12.0   \n",
       "\n",
       "  aspect_ratio movie_facebook_likes  imdb_score  \n",
       "0         1.78                33000         7.9  \n",
       "1         2.35                    0         7.1  \n",
       "2         2.35                85000         6.8  \n",
       "3         2.35               164000         8.5  \n",
       "4          NaN                    0         7.1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"ipynb_tmp\\profile_5276707535.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fa28223cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5787 observations of 38 variables in which 21 variables are numeric and 11 variables are categorical. The response variable “imdb_score” is numerical, and the predictors are mixed with numerical and categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>2.2. Remove Duplicates</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the IMDB dataset, There is 744 (12.9%) duplicate rows. I want to remove the 744 duplicated rows and keep the unique ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5043 entries, 0 to 5042\n",
      "Data columns (total 38 columns):\n",
      "id                                      5043 non-null int64\n",
      "stock_market_idx                        5043 non-null int64\n",
      "days_since_last_tweet                   5043 non-null int64\n",
      "pre_screen_viewers                      5043 non-null int64\n",
      "characters_per_longest_review           5043 non-null int64\n",
      "priority                                5043 non-null int64\n",
      "longest_facebook_comment_review_char    5043 non-null int64\n",
      "color                                   5024 non-null object\n",
      "director_name                           4939 non-null object\n",
      "num_critic_for_reviews                  4993 non-null float64\n",
      "duration                                5028 non-null float64\n",
      "director_facebook_likes                 4939 non-null float64\n",
      "actor_3_facebook_likes                  5020 non-null float64\n",
      "actor_2_name                            5030 non-null object\n",
      "actor_1_facebook_likes                  5036 non-null float64\n",
      "gross                                   4159 non-null float64\n",
      "genres                                  5043 non-null object\n",
      "actor_1_name                            5036 non-null object\n",
      "movie_title                             5043 non-null object\n",
      "num_voted_users                         5043 non-null int64\n",
      "cast_total_facebook_likes               5043 non-null int64\n",
      "made_up_column                          5043 non-null float64\n",
      "actor_3_name                            5020 non-null object\n",
      "facenumber_in_poster                    5030 non-null float64\n",
      "plot_keywords                           4890 non-null object\n",
      "movie_imdb_link                         5043 non-null object\n",
      "num_user_for_reviews                    5022 non-null float64\n",
      "language                                5031 non-null object\n",
      "country                                 5038 non-null object\n",
      "content_rating                          4740 non-null object\n",
      "website_score                           5043 non-null float64\n",
      "budget                                  4551 non-null float64\n",
      "weighted_budget                         5043 non-null int64\n",
      "title_year                              4935 non-null float64\n",
      "actor_2_facebook_likes                  5030 non-null float64\n",
      "aspect_ratio                            4714 non-null float64\n",
      "movie_facebook_likes                    5043 non-null int64\n",
      "imdb_score                              5043 non-null float64\n",
      "dtypes: float64(15), int64(11), object(12)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#drop the duplicates\n",
    "df1.drop_duplicates(inplace=True)\n",
    "# Check if done\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"cleaning_the_data\">\n",
    "     <h2>3. Data Cleaning</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>3.1 Missing Values</b></li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can quickly check if we have any null values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis_values(df1):\n",
    "    mis_value = df1.isnull().sum() \n",
    "    mis_value_per = 100 * df1.isnull().sum() / len(df1)\n",
    "    mis_value_column = pd.concat([mis_value, mis_value_per], axis=1)\n",
    "    mis_val_tab_rename_cols = mis_value_column.rename(columns = {0 : 'Missing Values', 1 : '% of Total Missing Values'})\n",
    "    mis_val_tab_rename_cols = mis_val_tab_rename_cols[mis_val_tab_rename_cols.iloc[:,1] != 0].sort_values('% of Total Missing Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"  \n",
    "           \n",
    "           \"There are \" + str(mis_val_tab_rename_cols.shape[0]) +\n",
    "           \" cols that have missing values.\")\n",
    "    return mis_val_tab_rename_cols     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 38 columns.\n",
      "There are 21 cols that have missing values.\n"
     ]
    }
   ],
   "source": [
    "missing_values = mis_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Missing Values  % of Total Missing Values\n",
      "gross                               884                       17.5\n",
      "budget                              492                        9.8\n",
      "aspect_ratio                        329                        6.5\n",
      "content_rating                      303                        6.0\n",
      "plot_keywords                       153                        3.0\n",
      "title_year                          108                        2.1\n",
      "director_name                       104                        2.1\n",
      "director_facebook_likes             104                        2.1\n",
      "num_critic_for_reviews               50                        1.0\n",
      "actor_3_name                         23                        0.5\n",
      "actor_3_facebook_likes               23                        0.5\n",
      "num_user_for_reviews                 21                        0.4\n",
      "color                                19                        0.4\n",
      "duration                             15                        0.3\n",
      "facenumber_in_poster                 13                        0.3\n",
      "actor_2_name                         13                        0.3\n",
      "actor_2_facebook_likes               13                        0.3\n",
      "language                             12                        0.2\n",
      "actor_1_name                          7                        0.1\n",
      "actor_1_facebook_likes                7                        0.1\n",
      "country                               5                        0.1\n"
     ]
    }
   ],
   "source": [
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of dropping the rows, I used the median imputation because it's maintain the distribution of the variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with median column values\n",
    "df1 = df1.fillna(df1.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_market_idx</th>\n",
       "      <th>days_since_last_tweet</th>\n",
       "      <th>pre_screen_viewers</th>\n",
       "      <th>characters_per_longest_review</th>\n",
       "      <th>priority</th>\n",
       "      <th>longest_facebook_comment_review_char</th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>website_score</th>\n",
       "      <th>budget</th>\n",
       "      <th>weighted_budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>1181</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.9</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>236999000</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1117</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>1196</td>\n",
       "      <td>4</td>\n",
       "      <td>740</td>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.1</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>299999000</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>1125</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.8</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>244999000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1127</td>\n",
       "      <td>4</td>\n",
       "      <td>1074</td>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.5</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1128</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1072</td>\n",
       "      <td>4</td>\n",
       "      <td>813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.1</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>1121</td>\n",
       "      <td>4</td>\n",
       "      <td>508</td>\n",
       "      <td>Color</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>462.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.6</td>\n",
       "      <td>263700000.0</td>\n",
       "      <td>263699000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>24000</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1021</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>1129</td>\n",
       "      <td>4</td>\n",
       "      <td>1189</td>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Raimi</td>\n",
       "      <td>392.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.2</td>\n",
       "      <td>258000000.0</td>\n",
       "      <td>257999000</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1133</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>1164</td>\n",
       "      <td>4</td>\n",
       "      <td>842</td>\n",
       "      <td>Color</td>\n",
       "      <td>Nathan Greno</td>\n",
       "      <td>324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>7.8</td>\n",
       "      <td>260000000.0</td>\n",
       "      <td>259999000</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>29000</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1186</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1076</td>\n",
       "      <td>4</td>\n",
       "      <td>1860</td>\n",
       "      <td>Color</td>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.5</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>118000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1040</td>\n",
       "      <td>4</td>\n",
       "      <td>832</td>\n",
       "      <td>Color</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG</td>\n",
       "      <td>7.5</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>10000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1142</td>\n",
       "      <td>99</td>\n",
       "      <td>13</td>\n",
       "      <td>1191</td>\n",
       "      <td>4</td>\n",
       "      <td>637</td>\n",
       "      <td>Color</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>673.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.9</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>197000</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1197</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>1154</td>\n",
       "      <td>4</td>\n",
       "      <td>1083</td>\n",
       "      <td>Color</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.1</td>\n",
       "      <td>209000000.0</td>\n",
       "      <td>208999000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1105</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1019</td>\n",
       "      <td>4</td>\n",
       "      <td>429</td>\n",
       "      <td>Color</td>\n",
       "      <td>Marc Forster</td>\n",
       "      <td>403.0</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>199999000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1145</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1045</td>\n",
       "      <td>4</td>\n",
       "      <td>1506</td>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>313.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.3</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>224999000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5000</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1010</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1135</td>\n",
       "      <td>4</td>\n",
       "      <td>1389</td>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.5</td>\n",
       "      <td>215000000.0</td>\n",
       "      <td>214999000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>48000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1146</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>1163</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>Color</td>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>733.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.2</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>224999000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>118000</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1188</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1066</td>\n",
       "      <td>4</td>\n",
       "      <td>829</td>\n",
       "      <td>Color</td>\n",
       "      <td>Andrew Adamson</td>\n",
       "      <td>258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>6.6</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>224999000</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1156</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>1020</td>\n",
       "      <td>4</td>\n",
       "      <td>1256</td>\n",
       "      <td>Color</td>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.1</td>\n",
       "      <td>220000000.0</td>\n",
       "      <td>219999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>123000</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1185</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>1165</td>\n",
       "      <td>4</td>\n",
       "      <td>729</td>\n",
       "      <td>Color</td>\n",
       "      <td>Rob Marshall</td>\n",
       "      <td>448.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>58000</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1127</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "      <td>1142</td>\n",
       "      <td>4</td>\n",
       "      <td>737</td>\n",
       "      <td>Color</td>\n",
       "      <td>Barry Sonnenfeld</td>\n",
       "      <td>451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.8</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>224999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>40000</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1051</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>1057</td>\n",
       "      <td>4</td>\n",
       "      <td>557</td>\n",
       "      <td>Color</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>422.0</td>\n",
       "      <td>...</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.5</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>65000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1015</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>1147</td>\n",
       "      <td>4</td>\n",
       "      <td>659</td>\n",
       "      <td>Color</td>\n",
       "      <td>Marc Webb</td>\n",
       "      <td>599.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>230000000.0</td>\n",
       "      <td>229999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>56000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1200</td>\n",
       "      <td>75</td>\n",
       "      <td>14</td>\n",
       "      <td>1103</td>\n",
       "      <td>4</td>\n",
       "      <td>1742</td>\n",
       "      <td>Color</td>\n",
       "      <td>Ridley Scott</td>\n",
       "      <td>343.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>199999000</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>17000</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1163</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>1092</td>\n",
       "      <td>4</td>\n",
       "      <td>1770</td>\n",
       "      <td>Color</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>509.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.9</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>224999000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>83000</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1042</td>\n",
       "      <td>73</td>\n",
       "      <td>19</td>\n",
       "      <td>1005</td>\n",
       "      <td>4</td>\n",
       "      <td>1028</td>\n",
       "      <td>Color</td>\n",
       "      <td>Chris Weitz</td>\n",
       "      <td>251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.1</td>\n",
       "      <td>180000000.0</td>\n",
       "      <td>179999000</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1142</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>1134</td>\n",
       "      <td>4</td>\n",
       "      <td>590</td>\n",
       "      <td>Color</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>446.0</td>\n",
       "      <td>...</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.2</td>\n",
       "      <td>207000000.0</td>\n",
       "      <td>206999000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1086</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>1035</td>\n",
       "      <td>4</td>\n",
       "      <td>390</td>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>315.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.7</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>199999000</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>26000</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1114</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>1125</td>\n",
       "      <td>4</td>\n",
       "      <td>760</td>\n",
       "      <td>Color</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>516.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>8.2</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>249999000</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>72000</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1197</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>1158</td>\n",
       "      <td>4</td>\n",
       "      <td>1413</td>\n",
       "      <td>Color</td>\n",
       "      <td>Peter Berg</td>\n",
       "      <td>377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>5.9</td>\n",
       "      <td>209000000.0</td>\n",
       "      <td>208999000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>44000</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1196</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>1022</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>Color</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150000000.0</td>\n",
       "      <td>149999000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>150000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>5014</td>\n",
       "      <td>1081</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>1171</td>\n",
       "      <td>4</td>\n",
       "      <td>1530</td>\n",
       "      <td>Color</td>\n",
       "      <td>Eric Eason</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>23000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>61</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>5015</td>\n",
       "      <td>1174</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1091</td>\n",
       "      <td>4</td>\n",
       "      <td>1897</td>\n",
       "      <td>Color</td>\n",
       "      <td>Uwe Boll</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>R</td>\n",
       "      <td>6.3</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>5016</td>\n",
       "      <td>1186</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1101</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>Black and White</td>\n",
       "      <td>Richard Linklater</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>7.1</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>22000</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2000</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>5017</td>\n",
       "      <td>1136</td>\n",
       "      <td>59</td>\n",
       "      <td>11</td>\n",
       "      <td>1172</td>\n",
       "      <td>4</td>\n",
       "      <td>1724</td>\n",
       "      <td>Color</td>\n",
       "      <td>Joseph Mazzella</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>24000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>33</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>5018</td>\n",
       "      <td>1110</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1012</td>\n",
       "      <td>4</td>\n",
       "      <td>1022</td>\n",
       "      <td>Color</td>\n",
       "      <td>Travis Legge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>21000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>200</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>5019</td>\n",
       "      <td>1040</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>1170</td>\n",
       "      <td>4</td>\n",
       "      <td>1434</td>\n",
       "      <td>Color</td>\n",
       "      <td>Alex Kendrick</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>19000</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>725</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>5020</td>\n",
       "      <td>1183</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>675</td>\n",
       "      <td>Color</td>\n",
       "      <td>Marcus Nispel</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>4.6</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>5021</td>\n",
       "      <td>1155</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>1140</td>\n",
       "      <td>4</td>\n",
       "      <td>625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Landers</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17350.0</td>\n",
       "      <td>16350</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>5022</td>\n",
       "      <td>1027</td>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "      <td>1002</td>\n",
       "      <td>4</td>\n",
       "      <td>1479</td>\n",
       "      <td>Color</td>\n",
       "      <td>Jay Duplass</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>14000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>297</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>5023</td>\n",
       "      <td>1190</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1105</td>\n",
       "      <td>4</td>\n",
       "      <td>221</td>\n",
       "      <td>Black and White</td>\n",
       "      <td>Jim Chuchu</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>14000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>45</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023</th>\n",
       "      <td>5024</td>\n",
       "      <td>1138</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1064</td>\n",
       "      <td>4</td>\n",
       "      <td>923</td>\n",
       "      <td>Color</td>\n",
       "      <td>Daryl Wein</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>14000</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>324</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>5025</td>\n",
       "      <td>1055</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>1828</td>\n",
       "      <td>Color</td>\n",
       "      <td>Jason Trost</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>19000</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>835</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025</th>\n",
       "      <td>5026</td>\n",
       "      <td>1125</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>1086</td>\n",
       "      <td>4</td>\n",
       "      <td>1342</td>\n",
       "      <td>Color</td>\n",
       "      <td>John Waters</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>6.1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>5027</td>\n",
       "      <td>1170</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1003</td>\n",
       "      <td>4</td>\n",
       "      <td>971</td>\n",
       "      <td>Color</td>\n",
       "      <td>Olivier Assayas</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>France</td>\n",
       "      <td>R</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3500</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>171</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>5028</td>\n",
       "      <td>1157</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "      <td>1095</td>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>Color</td>\n",
       "      <td>Jafar Panahi</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>697</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>5029</td>\n",
       "      <td>1122</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>1108</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>Black and White</td>\n",
       "      <td>Ivan Kavanagh</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>105</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>5030</td>\n",
       "      <td>1056</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>1146</td>\n",
       "      <td>4</td>\n",
       "      <td>1489</td>\n",
       "      <td>Color</td>\n",
       "      <td>Kiyoshi Kurosawa</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>999000</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>817</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>5031</td>\n",
       "      <td>1193</td>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "      <td>1027</td>\n",
       "      <td>4</td>\n",
       "      <td>684</td>\n",
       "      <td>Color</td>\n",
       "      <td>Tadeo Garcia</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>22</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>5032</td>\n",
       "      <td>1196</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>1036</td>\n",
       "      <td>4</td>\n",
       "      <td>1121</td>\n",
       "      <td>Color</td>\n",
       "      <td>Thomas L. Phillips</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>199000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>424</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>5033</td>\n",
       "      <td>1026</td>\n",
       "      <td>76</td>\n",
       "      <td>20</td>\n",
       "      <td>1177</td>\n",
       "      <td>4</td>\n",
       "      <td>1091</td>\n",
       "      <td>Color</td>\n",
       "      <td>Ash Baron-Cohen</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>5034</td>\n",
       "      <td>1177</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>1159</td>\n",
       "      <td>4</td>\n",
       "      <td>1365</td>\n",
       "      <td>Color</td>\n",
       "      <td>Shane Carruth</td>\n",
       "      <td>143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>19000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>5035</td>\n",
       "      <td>1060</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>1133</td>\n",
       "      <td>4</td>\n",
       "      <td>181</td>\n",
       "      <td>Color</td>\n",
       "      <td>Neill Dela Llana</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>74</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>5036</td>\n",
       "      <td>1167</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1152</td>\n",
       "      <td>4</td>\n",
       "      <td>1497</td>\n",
       "      <td>Color</td>\n",
       "      <td>Robert Rodriguez</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>5037</td>\n",
       "      <td>1062</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>1059</td>\n",
       "      <td>4</td>\n",
       "      <td>373</td>\n",
       "      <td>Color</td>\n",
       "      <td>Anthony Vallone</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>5038</td>\n",
       "      <td>1013</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>1187</td>\n",
       "      <td>4</td>\n",
       "      <td>766</td>\n",
       "      <td>Color</td>\n",
       "      <td>Edward Burns</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>6.4</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>413</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>5039</td>\n",
       "      <td>1131</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>1073</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Color</td>\n",
       "      <td>Scott Smith</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>84</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>5040</td>\n",
       "      <td>1016</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>1002</td>\n",
       "      <td>4</td>\n",
       "      <td>539</td>\n",
       "      <td>Color</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>7.5</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>5041</td>\n",
       "      <td>1146</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>1021</td>\n",
       "      <td>4</td>\n",
       "      <td>1558</td>\n",
       "      <td>Color</td>\n",
       "      <td>Benjamin Roberds</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>400</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>16</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>5042</td>\n",
       "      <td>1015</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>1020</td>\n",
       "      <td>4</td>\n",
       "      <td>1152</td>\n",
       "      <td>Color</td>\n",
       "      <td>Daniel Hsia</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>6.3</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>660</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>5043</td>\n",
       "      <td>1048</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1081</td>\n",
       "      <td>4</td>\n",
       "      <td>1587</td>\n",
       "      <td>Color</td>\n",
       "      <td>Jon Gunn</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>456</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5043 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  stock_market_idx  days_since_last_tweet  pre_screen_viewers  \\\n",
       "0        1              1102                     67                  18   \n",
       "1        2              1117                     70                  18   \n",
       "2        3              1000                     90                  11   \n",
       "3        4              1007                     35                  10   \n",
       "4        5              1128                     85                  20   \n",
       "5        6              1037                     75                  20   \n",
       "6        7              1021                     80                  12   \n",
       "7        8              1133                     30                  16   \n",
       "8        9              1186                     14                  11   \n",
       "9       10              1016                      3                  10   \n",
       "10      11              1142                     99                  13   \n",
       "11      12              1197                     35                  17   \n",
       "12      13              1105                     17                  12   \n",
       "13      14              1145                      8                  10   \n",
       "14      15              1010                     14                  15   \n",
       "15      16              1146                     89                  14   \n",
       "16      17              1188                     12                  18   \n",
       "17      18              1156                     17                  12   \n",
       "18      19              1185                     59                  12   \n",
       "19      20              1127                     77                  11   \n",
       "20      21              1051                     36                  19   \n",
       "21      22              1015                     61                  19   \n",
       "22      23              1200                     75                  14   \n",
       "23      24              1163                     45                  10   \n",
       "24      25              1042                     73                  19   \n",
       "25      26              1142                     96                  16   \n",
       "26      27              1086                     28                  19   \n",
       "27      28              1114                     41                  13   \n",
       "28      29              1197                     66                  16   \n",
       "29      30              1196                     23                  19   \n",
       "...    ...               ...                    ...                 ...   \n",
       "5013  5014              1081                     57                  10   \n",
       "5014  5015              1174                     77                  12   \n",
       "5015  5016              1186                     15                  19   \n",
       "5016  5017              1136                     59                  11   \n",
       "5017  5018              1110                     19                  10   \n",
       "5018  5019              1040                     66                  19   \n",
       "5019  5020              1183                     43                  19   \n",
       "5020  5021              1155                     61                  11   \n",
       "5021  5022              1027                     96                  11   \n",
       "5022  5023              1190                     13                  13   \n",
       "5023  5024              1138                     77                  12   \n",
       "5024  5025              1055                     13                  16   \n",
       "5025  5026              1125                     97                  12   \n",
       "5026  5027              1170                     58                  10   \n",
       "5027  5028              1157                     98                  16   \n",
       "5028  5029              1122                     69                  19   \n",
       "5029  5030              1056                     49                  20   \n",
       "5030  5031              1193                     97                  18   \n",
       "5031  5032              1196                     31                  15   \n",
       "5032  5033              1026                     76                  20   \n",
       "5033  5034              1177                     84                  11   \n",
       "5034  5035              1060                     59                  16   \n",
       "5035  5036              1167                      2                  10   \n",
       "5036  5037              1062                     45                  12   \n",
       "5037  5038              1013                     57                  13   \n",
       "5038  5039              1131                     42                  19   \n",
       "5039  5040              1016                     26                  11   \n",
       "5040  5041              1146                     33                  18   \n",
       "5041  5042              1015                     31                  11   \n",
       "5042  5043              1048                      9                  19   \n",
       "\n",
       "      characters_per_longest_review  priority  \\\n",
       "0                              1181         4   \n",
       "1                              1196         4   \n",
       "2                              1125         4   \n",
       "3                              1127         4   \n",
       "4                              1072         4   \n",
       "5                              1121         4   \n",
       "6                              1129         4   \n",
       "7                              1164         4   \n",
       "8                              1076         4   \n",
       "9                              1040         4   \n",
       "10                             1191         4   \n",
       "11                             1154         4   \n",
       "12                             1019         4   \n",
       "13                             1045         4   \n",
       "14                             1135         4   \n",
       "15                             1163         4   \n",
       "16                             1066         4   \n",
       "17                             1020         4   \n",
       "18                             1165         4   \n",
       "19                             1142         4   \n",
       "20                             1057         4   \n",
       "21                             1147         4   \n",
       "22                             1103         4   \n",
       "23                             1092         4   \n",
       "24                             1005         4   \n",
       "25                             1134         4   \n",
       "26                             1035         4   \n",
       "27                             1125         4   \n",
       "28                             1158         4   \n",
       "29                             1022         4   \n",
       "...                             ...       ...   \n",
       "5013                           1171         4   \n",
       "5014                           1091         4   \n",
       "5015                           1101         4   \n",
       "5016                           1172         4   \n",
       "5017                           1012         4   \n",
       "5018                           1170         4   \n",
       "5019                           1074         4   \n",
       "5020                           1140         4   \n",
       "5021                           1002         4   \n",
       "5022                           1105         4   \n",
       "5023                           1064         4   \n",
       "5024                           1097         4   \n",
       "5025                           1086         4   \n",
       "5026                           1003         4   \n",
       "5027                           1095         4   \n",
       "5028                           1108         4   \n",
       "5029                           1146         4   \n",
       "5030                           1027         4   \n",
       "5031                           1036         4   \n",
       "5032                           1177         4   \n",
       "5033                           1159         4   \n",
       "5034                           1133         4   \n",
       "5035                           1152         4   \n",
       "5036                           1059         4   \n",
       "5037                           1187         4   \n",
       "5038                           1073         4   \n",
       "5039                           1002         4   \n",
       "5040                           1021         4   \n",
       "5041                           1020         4   \n",
       "5042                           1081         4   \n",
       "\n",
       "      longest_facebook_comment_review_char             color  \\\n",
       "0                                      250             Color   \n",
       "1                                      740             Color   \n",
       "2                                     1779             Color   \n",
       "3                                     1074             Color   \n",
       "4                                      813               NaN   \n",
       "5                                      508             Color   \n",
       "6                                     1189             Color   \n",
       "7                                      842             Color   \n",
       "8                                     1860             Color   \n",
       "9                                      832             Color   \n",
       "10                                     637             Color   \n",
       "11                                    1083             Color   \n",
       "12                                     429             Color   \n",
       "13                                    1506             Color   \n",
       "14                                    1389             Color   \n",
       "15                                      87             Color   \n",
       "16                                     829             Color   \n",
       "17                                    1256             Color   \n",
       "18                                     729             Color   \n",
       "19                                     737             Color   \n",
       "20                                     557             Color   \n",
       "21                                     659             Color   \n",
       "22                                    1742             Color   \n",
       "23                                    1770             Color   \n",
       "24                                    1028             Color   \n",
       "25                                     590             Color   \n",
       "26                                     390             Color   \n",
       "27                                     760             Color   \n",
       "28                                    1413             Color   \n",
       "29                                      91             Color   \n",
       "...                                    ...               ...   \n",
       "5013                                  1530             Color   \n",
       "5014                                  1897             Color   \n",
       "5015                                   999   Black and White   \n",
       "5016                                  1724             Color   \n",
       "5017                                  1022             Color   \n",
       "5018                                  1434             Color   \n",
       "5019                                   675             Color   \n",
       "5020                                   625               NaN   \n",
       "5021                                  1479             Color   \n",
       "5022                                   221   Black and White   \n",
       "5023                                   923             Color   \n",
       "5024                                  1828             Color   \n",
       "5025                                  1342             Color   \n",
       "5026                                   971             Color   \n",
       "5027                                  1145             Color   \n",
       "5028                                   311   Black and White   \n",
       "5029                                  1489             Color   \n",
       "5030                                   684             Color   \n",
       "5031                                  1121             Color   \n",
       "5032                                  1091             Color   \n",
       "5033                                  1365             Color   \n",
       "5034                                   181             Color   \n",
       "5035                                  1497             Color   \n",
       "5036                                   373             Color   \n",
       "5037                                   766             Color   \n",
       "5038                                    10             Color   \n",
       "5039                                   539             Color   \n",
       "5040                                  1558             Color   \n",
       "5041                                  1152             Color   \n",
       "5042                                  1587             Color   \n",
       "\n",
       "           director_name  num_critic_for_reviews     ...          country  \\\n",
       "0          James Cameron                   723.0     ...              USA   \n",
       "1         Gore Verbinski                   302.0     ...              USA   \n",
       "2             Sam Mendes                   602.0     ...               UK   \n",
       "3      Christopher Nolan                   813.0     ...              USA   \n",
       "4            Doug Walker                   110.0     ...              NaN   \n",
       "5         Andrew Stanton                   462.0     ...              USA   \n",
       "6              Sam Raimi                   392.0     ...              USA   \n",
       "7           Nathan Greno                   324.0     ...              USA   \n",
       "8            Joss Whedon                   635.0     ...              USA   \n",
       "9            David Yates                   375.0     ...               UK   \n",
       "10           Zack Snyder                   673.0     ...              USA   \n",
       "11          Bryan Singer                   434.0     ...              USA   \n",
       "12          Marc Forster                   403.0     ...               UK   \n",
       "13        Gore Verbinski                   313.0     ...              USA   \n",
       "14        Gore Verbinski                   450.0     ...              USA   \n",
       "15           Zack Snyder                   733.0     ...              USA   \n",
       "16        Andrew Adamson                   258.0     ...              USA   \n",
       "17           Joss Whedon                   703.0     ...              USA   \n",
       "18          Rob Marshall                   448.0     ...              USA   \n",
       "19      Barry Sonnenfeld                   451.0     ...              USA   \n",
       "20         Peter Jackson                   422.0     ...      New Zealand   \n",
       "21             Marc Webb                   599.0     ...              USA   \n",
       "22          Ridley Scott                   343.0     ...              USA   \n",
       "23         Peter Jackson                   509.0     ...              USA   \n",
       "24           Chris Weitz                   251.0     ...              USA   \n",
       "25         Peter Jackson                   446.0     ...      New Zealand   \n",
       "26         James Cameron                   315.0     ...              USA   \n",
       "27         Anthony Russo                   516.0     ...              USA   \n",
       "28            Peter Berg                   377.0     ...              USA   \n",
       "29       Colin Trevorrow                   644.0     ...              USA   \n",
       "...                  ...                     ...     ...              ...   \n",
       "5013          Eric Eason                    28.0     ...              USA   \n",
       "5014            Uwe Boll                    58.0     ...           Canada   \n",
       "5015   Richard Linklater                    61.0     ...              USA   \n",
       "5016     Joseph Mazzella                   110.0     ...              USA   \n",
       "5017        Travis Legge                     1.0     ...              USA   \n",
       "5018       Alex Kendrick                     5.0     ...              USA   \n",
       "5019       Marcus Nispel                    43.0     ...              USA   \n",
       "5020     Brandon Landers                   110.0     ...              USA   \n",
       "5021         Jay Duplass                    51.0     ...              USA   \n",
       "5022          Jim Chuchu                     6.0     ...            Kenya   \n",
       "5023          Daryl Wein                    22.0     ...              USA   \n",
       "5024         Jason Trost                    42.0     ...              USA   \n",
       "5025         John Waters                    73.0     ...              USA   \n",
       "5026     Olivier Assayas                    81.0     ...           France   \n",
       "5027        Jafar Panahi                    64.0     ...             Iran   \n",
       "5028       Ivan Kavanagh                    12.0     ...          Ireland   \n",
       "5029    Kiyoshi Kurosawa                    78.0     ...            Japan   \n",
       "5030        Tadeo Garcia                   110.0     ...              USA   \n",
       "5031  Thomas L. Phillips                    13.0     ...              USA   \n",
       "5032     Ash Baron-Cohen                    10.0     ...              USA   \n",
       "5033       Shane Carruth                   143.0     ...              USA   \n",
       "5034    Neill Dela Llana                    35.0     ...      Philippines   \n",
       "5035    Robert Rodriguez                    56.0     ...              USA   \n",
       "5036     Anthony Vallone                   110.0     ...              USA   \n",
       "5037        Edward Burns                    14.0     ...              USA   \n",
       "5038         Scott Smith                     1.0     ...           Canada   \n",
       "5039                 NaN                    43.0     ...              USA   \n",
       "5040    Benjamin Roberds                    13.0     ...              USA   \n",
       "5041         Daniel Hsia                    14.0     ...              USA   \n",
       "5042            Jon Gunn                    43.0     ...              USA   \n",
       "\n",
       "      content_rating  website_score       budget  weighted_budget  title_year  \\\n",
       "0              PG-13            7.9  237000000.0        236999000      2009.0   \n",
       "1              PG-13            7.1  300000000.0        299999000      2007.0   \n",
       "2              PG-13            6.8  245000000.0        244999000      2015.0   \n",
       "3              PG-13            8.5  250000000.0        249999000      2012.0   \n",
       "4                NaN            7.1   20000000.0            -1000      2005.0   \n",
       "5              PG-13            6.6  263700000.0        263699000      2012.0   \n",
       "6              PG-13            6.2  258000000.0        257999000      2007.0   \n",
       "7                 PG            7.8  260000000.0        259999000      2010.0   \n",
       "8              PG-13            7.5  250000000.0        249999000      2015.0   \n",
       "9                 PG            7.5  250000000.0        249999000      2009.0   \n",
       "10             PG-13            6.9  250000000.0        249999000      2016.0   \n",
       "11             PG-13            6.1  209000000.0        208999000      2006.0   \n",
       "12             PG-13            6.7  200000000.0        199999000      2008.0   \n",
       "13             PG-13            7.3  225000000.0        224999000      2006.0   \n",
       "14             PG-13            6.5  215000000.0        214999000      2013.0   \n",
       "15             PG-13            7.2  225000000.0        224999000      2013.0   \n",
       "16                PG            6.6  225000000.0        224999000      2008.0   \n",
       "17             PG-13            8.1  220000000.0        219999000      2012.0   \n",
       "18             PG-13            6.7  250000000.0        249999000      2011.0   \n",
       "19             PG-13            6.8  225000000.0        224999000      2012.0   \n",
       "20             PG-13            7.5  250000000.0        249999000      2014.0   \n",
       "21             PG-13            7.0  230000000.0        229999000      2012.0   \n",
       "22             PG-13            6.7  200000000.0        199999000      2010.0   \n",
       "23             PG-13            7.9  225000000.0        224999000      2013.0   \n",
       "24             PG-13            6.1  180000000.0        179999000      2007.0   \n",
       "25             PG-13            7.2  207000000.0        206999000      2005.0   \n",
       "26             PG-13            7.7  200000000.0        199999000      1997.0   \n",
       "27             PG-13            8.2  250000000.0        249999000      2016.0   \n",
       "28             PG-13            5.9  209000000.0        208999000      2012.0   \n",
       "29             PG-13            7.0  150000000.0        149999000      2015.0   \n",
       "...              ...            ...          ...              ...         ...   \n",
       "5013             NaN            7.0      24000.0            23000      2002.0   \n",
       "5014               R            6.3   20000000.0            -1000      2009.0   \n",
       "5015               R            7.1      23000.0            22000      1991.0   \n",
       "5016             NaN            4.8      25000.0            24000      2015.0   \n",
       "5017             NaN            3.3      22000.0            21000      2013.0   \n",
       "5018             NaN            6.9      20000.0            19000      2003.0   \n",
       "5019               R            4.6   20000000.0            -1000      2015.0   \n",
       "5020             NaN            3.0      17350.0            16350      2011.0   \n",
       "5021               R            6.6      15000.0            14000      2005.0   \n",
       "5022             NaN            7.4      15000.0            14000      2014.0   \n",
       "5023             NaN            6.2      15000.0            14000      2009.0   \n",
       "5024         Unrated            4.0      20000.0            19000      2011.0   \n",
       "5025           NC-17            6.1      10000.0             9000      1972.0   \n",
       "5026               R            6.9       4500.0             3500      2004.0   \n",
       "5027       Not Rated            7.5      10000.0             9000      2000.0   \n",
       "5028             NaN            6.7      10000.0             9000      2007.0   \n",
       "5029             NaN            7.4    1000000.0           999000      1997.0   \n",
       "5030             NaN            6.1   20000000.0            -1000      2004.0   \n",
       "5031             NaN            5.4     200000.0           199000      2012.0   \n",
       "5032             NaN            6.4   20000000.0            -1000      1995.0   \n",
       "5033           PG-13            7.0       7000.0             6000      2004.0   \n",
       "5034       Not Rated            6.3       7000.0             6000      2005.0   \n",
       "5035               R            6.9       7000.0             6000      1992.0   \n",
       "5036           PG-13            7.8       3250.0             2250      2005.0   \n",
       "5037       Not Rated            6.4       9000.0             8000      2011.0   \n",
       "5038             NaN            7.7   20000000.0            -1000      2013.0   \n",
       "5039           TV-14            7.5   20000000.0            -1000      2005.0   \n",
       "5040             NaN            6.3       1400.0              400      2013.0   \n",
       "5041           PG-13            6.3   20000000.0            -1000      2012.0   \n",
       "5042              PG            6.6       1100.0              100      2004.0   \n",
       "\n",
       "     actor_2_facebook_likes aspect_ratio movie_facebook_likes  imdb_score  \n",
       "0                     936.0         1.78                33000         7.9  \n",
       "1                    5000.0         2.35                    0         7.1  \n",
       "2                     393.0         2.35                85000         6.8  \n",
       "3                   23000.0         2.35               164000         8.5  \n",
       "4                      12.0         2.35                    0         7.1  \n",
       "5                     632.0         2.35                24000         6.6  \n",
       "6                   11000.0         2.35                    0         6.2  \n",
       "7                     553.0         1.85                29000         7.8  \n",
       "8                   21000.0         2.35               118000         7.5  \n",
       "9                   11000.0         2.35                10000         7.5  \n",
       "10                   4000.0         2.35               197000         6.9  \n",
       "11                  10000.0         2.35                    0         6.1  \n",
       "12                    412.0         2.35                    0         6.7  \n",
       "13                   5000.0         2.35                 5000         7.3  \n",
       "14                   2000.0         2.35                48000         6.5  \n",
       "15                   3000.0         2.35               118000         7.2  \n",
       "16                    216.0         2.35                    0         6.6  \n",
       "17                  21000.0         1.85               123000         8.1  \n",
       "18                  11000.0         2.35                58000         6.7  \n",
       "19                    816.0         1.85                40000         6.8  \n",
       "20                    972.0         2.35                65000         7.5  \n",
       "21                  10000.0         2.35                56000         7.0  \n",
       "22                    882.0         2.35                17000         6.7  \n",
       "23                    972.0         2.35                83000         7.9  \n",
       "24                   6000.0         2.35                    0         6.1  \n",
       "25                    919.0         2.35                    0         7.2  \n",
       "26                  14000.0         2.35                26000         7.7  \n",
       "27                  19000.0         2.35                72000         8.2  \n",
       "28                  10000.0         2.35                44000         5.9  \n",
       "29                   2000.0         2.00               150000         7.0  \n",
       "...                     ...          ...                  ...         ...  \n",
       "5013                   46.0         1.78                   61         7.0  \n",
       "5014                  918.0         2.35                    0         6.3  \n",
       "5015                    0.0         1.37                 2000         7.1  \n",
       "5016                   25.0         2.35                   33         4.8  \n",
       "5017                  184.0         1.78                  200         3.3  \n",
       "5018                   49.0         1.85                  725         6.9  \n",
       "5019                  512.0         1.85                    0         4.6  \n",
       "5020                   19.0         2.35                   33         3.0  \n",
       "5021                  224.0         2.35                  297         6.6  \n",
       "5022                   19.0         2.35                   45         7.4  \n",
       "5023                  212.0         2.35                  324         6.2  \n",
       "5024                   91.0         2.35                  835         4.0  \n",
       "5025                  143.0         1.37                    0         6.1  \n",
       "5026                  133.0         2.35                  171         6.9  \n",
       "5027                    0.0         1.85                  697         7.5  \n",
       "5028                    5.0         1.33                  105         6.7  \n",
       "5029                   13.0         1.85                  817         7.4  \n",
       "5030                   20.0         2.35                   22         6.1  \n",
       "5031                   98.0        16.00                  424         5.4  \n",
       "5032                  194.0         2.35                   20         6.4  \n",
       "5033                   45.0         1.85                19000         7.0  \n",
       "5034                    0.0         2.35                   74         6.3  \n",
       "5035                   20.0         1.37                    0         6.9  \n",
       "5036                   44.0         2.35                    4         7.8  \n",
       "5037                  205.0         2.35                  413         6.4  \n",
       "5038                  470.0         2.35                   84         7.7  \n",
       "5039                  593.0        16.00                32000         7.5  \n",
       "5040                    0.0         2.35                   16         6.3  \n",
       "5041                  719.0         2.35                  660         6.3  \n",
       "5042                   23.0         1.85                  456         6.6  \n",
       "\n",
       "[5043 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    15\n",
       "object     12\n",
       "int64      11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We do! Let's use the \"describe\" method to find them, amongst other interesting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_market_idx</th>\n",
       "      <th>days_since_last_tweet</th>\n",
       "      <th>pre_screen_viewers</th>\n",
       "      <th>characters_per_longest_review</th>\n",
       "      <th>priority</th>\n",
       "      <th>longest_facebook_comment_review_char</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>...</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>website_score</th>\n",
       "      <th>budget</th>\n",
       "      <th>weighted_budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.00000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.0</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5.043000e+03</td>\n",
       "      <td>5.043000e+03</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>1101.16042</td>\n",
       "      <td>49.908190</td>\n",
       "      <td>14.979576</td>\n",
       "      <td>1100.040849</td>\n",
       "      <td>4.0</td>\n",
       "      <td>962.646242</td>\n",
       "      <td>139.894904</td>\n",
       "      <td>107.188578</td>\n",
       "      <td>673.362086</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370216</td>\n",
       "      <td>272.284553</td>\n",
       "      <td>6.559925</td>\n",
       "      <td>3.782554e+07</td>\n",
       "      <td>3.587332e+07</td>\n",
       "      <td>2002.531033</td>\n",
       "      <td>1649.030339</td>\n",
       "      <td>2.228858</td>\n",
       "      <td>7525.964505</td>\n",
       "      <td>6.559925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1455.933034</td>\n",
       "      <td>58.48476</td>\n",
       "      <td>28.432368</td>\n",
       "      <td>3.163246</td>\n",
       "      <td>57.299452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>541.710282</td>\n",
       "      <td>121.034214</td>\n",
       "      <td>25.160972</td>\n",
       "      <td>2785.636586</td>\n",
       "      <td>...</td>\n",
       "      <td>2.011066</td>\n",
       "      <td>377.269873</td>\n",
       "      <td>8.433695</td>\n",
       "      <td>1.958882e+08</td>\n",
       "      <td>1.961555e+08</td>\n",
       "      <td>12.359307</td>\n",
       "      <td>4037.579765</td>\n",
       "      <td>1.339542</td>\n",
       "      <td>19320.445110</td>\n",
       "      <td>8.433695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.180000e+02</td>\n",
       "      <td>-1.000000e+03</td>\n",
       "      <td>1916.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1261.500000</td>\n",
       "      <td>1051.00000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>2.999000e+06</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2522.000000</td>\n",
       "      <td>1101.00000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.499900e+07</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3782.500000</td>\n",
       "      <td>1153.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>3.999900e+07</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5043.000000</td>\n",
       "      <td>1200.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5060.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1.221550e+10</td>\n",
       "      <td>1.221550e+10</td>\n",
       "      <td>2045.000000</td>\n",
       "      <td>137000.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>349000.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  stock_market_idx  days_since_last_tweet  \\\n",
       "count  5043.000000        5043.00000            5043.000000   \n",
       "mean   2522.000000        1101.16042              49.908190   \n",
       "std    1455.933034          58.48476              28.432368   \n",
       "min       1.000000        1000.00000               1.000000   \n",
       "25%    1261.500000        1051.00000              26.000000   \n",
       "50%    2522.000000        1101.00000              49.000000   \n",
       "75%    3782.500000        1153.00000              74.000000   \n",
       "max    5043.000000        1200.00000              99.000000   \n",
       "\n",
       "       pre_screen_viewers  characters_per_longest_review  priority  \\\n",
       "count         5043.000000                    5043.000000    5043.0   \n",
       "mean            14.979576                    1100.040849       4.0   \n",
       "std              3.163246                      57.299452       0.0   \n",
       "min             10.000000                    1000.000000       4.0   \n",
       "25%             12.000000                    1051.000000       4.0   \n",
       "50%             15.000000                    1099.000000       4.0   \n",
       "75%             18.000000                    1149.000000       4.0   \n",
       "max             20.000000                    1200.000000       4.0   \n",
       "\n",
       "       longest_facebook_comment_review_char  num_critic_for_reviews  \\\n",
       "count                           5043.000000             5043.000000   \n",
       "mean                             962.646242              139.894904   \n",
       "std                              541.710282              121.034214   \n",
       "min                                6.000000                1.000000   \n",
       "25%                              511.000000               50.000000   \n",
       "50%                              962.000000              110.000000   \n",
       "75%                             1424.000000              194.000000   \n",
       "max                             1900.000000              813.000000   \n",
       "\n",
       "          duration  director_facebook_likes     ...       \\\n",
       "count  5043.000000              5043.000000     ...        \n",
       "mean    107.188578               673.362086     ...        \n",
       "std      25.160972              2785.636586     ...        \n",
       "min       7.000000                 0.000000     ...        \n",
       "25%      93.000000                 7.000000     ...        \n",
       "50%     103.000000                49.000000     ...        \n",
       "75%     118.000000               189.000000     ...        \n",
       "max     511.000000             23000.000000     ...        \n",
       "\n",
       "       facenumber_in_poster  num_user_for_reviews  website_score  \\\n",
       "count           5043.000000           5043.000000    5043.000000   \n",
       "mean               1.370216            272.284553       6.559925   \n",
       "std                2.011066            377.269873       8.433695   \n",
       "min                0.000000              1.000000       1.600000   \n",
       "25%                0.000000             65.000000       5.800000   \n",
       "50%                1.000000            156.000000       6.600000   \n",
       "75%                2.000000            324.000000       7.200000   \n",
       "max               43.000000           5060.000000     600.000000   \n",
       "\n",
       "             budget  weighted_budget   title_year  actor_2_facebook_likes  \\\n",
       "count  5.043000e+03     5.043000e+03  5043.000000             5043.000000   \n",
       "mean   3.782554e+07     3.587332e+07  2002.531033             1649.030339   \n",
       "std    1.958882e+08     1.961555e+08    12.359307             4037.579765   \n",
       "min    2.180000e+02    -1.000000e+03  1916.000000                0.000000   \n",
       "25%    7.000000e+06     2.999000e+06  1999.000000              281.000000   \n",
       "50%    2.000000e+07     1.499900e+07  2005.000000              595.000000   \n",
       "75%    4.000000e+07     3.999900e+07  2011.000000              918.000000   \n",
       "max    1.221550e+10     1.221550e+10  2045.000000           137000.000000   \n",
       "\n",
       "       aspect_ratio  movie_facebook_likes   imdb_score  \n",
       "count   5043.000000           5043.000000  5043.000000  \n",
       "mean       2.228858           7525.964505     6.559925  \n",
       "std        1.339542          19320.445110     8.433695  \n",
       "min        1.180000              0.000000     1.600000  \n",
       "25%        1.850000              0.000000     5.800000  \n",
       "50%        2.350000            166.000000     6.600000  \n",
       "75%        2.350000           3000.000000     7.200000  \n",
       "max       16.000000         349000.000000   600.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped the columns because these columns had high cardinality or many levels and also many zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extraneous columns\n",
    "col = ['id', 'priority', 'director_name', 'actor_2_name', 'color', 'actor_1_name', 'actor_3_name', 'country', \n",
    "       'director_name', 'facenumber_in_poster', 'movie_facebook_likes', 'website_score', 'weighted_budget', \n",
    "       'movie_imdb_link', 'content_rating', 'language', 'plot_keywords', 'cast_total_facebook_likes', \n",
    "       'director_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'movie_title', 'title_year', \n",
    "       'aspect_ratio', 'website_score', 'genres', 'actor_1_facebook_likes']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5043 entries, 0 to 5042\n",
      "Data columns (total 13 columns):\n",
      "stock_market_idx                        5043 non-null int64\n",
      "days_since_last_tweet                   5043 non-null int64\n",
      "pre_screen_viewers                      5043 non-null int64\n",
      "characters_per_longest_review           5043 non-null int64\n",
      "longest_facebook_comment_review_char    5043 non-null int64\n",
      "num_critic_for_reviews                  5043 non-null float64\n",
      "duration                                5043 non-null float64\n",
      "gross                                   5043 non-null float64\n",
      "num_voted_users                         5043 non-null int64\n",
      "made_up_column                          5043 non-null float64\n",
      "num_user_for_reviews                    5043 non-null float64\n",
      "budget                                  5043 non-null float64\n",
      "imdb_score                              5043 non-null float64\n",
      "dtypes: float64(7), int64(6)\n",
      "memory usage: 551.6 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"transforming_the_data\">\n",
    "     <h2>4. Data Transformation</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize the above variables, I used log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['budget'] = np.log(df1.budget)\n",
    "df1['imdb_score'] = np.log(df1.imdb_score)\n",
    "df1['made_up_column'] = np.log(df1.imdb_score)\n",
    "df1['stock_market_idx'] = np.log(df1.stock_market_idx)\n",
    "df1['days_since_last_tweet'] = np.log(df1.days_since_last_tweet)\n",
    "df1['pre_screen_viewers'] = np.log(df1.pre_screen_viewers)\n",
    "df1['characters_per_longest_review'] = np.log(df1.characters_per_longest_review)\n",
    "df1['longest_facebook_comment_review_char'] = np.log(df1.longest_facebook_comment_review_char)\n",
    "df1['num_critic_for_reviews'] = np.log(df1.num_critic_for_reviews)\n",
    "df1['duration'] = np.log(df1.duration)\n",
    "df1['gross'] = np.log(df1.gross)\n",
    "df1['num_voted_users'] = np.log(df1.num_voted_users)\n",
    "df1['num_user_for_reviews'] = np.log(df1.num_user_for_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_market_idx</th>\n",
       "      <th>days_since_last_tweet</th>\n",
       "      <th>pre_screen_viewers</th>\n",
       "      <th>characters_per_longest_review</th>\n",
       "      <th>longest_facebook_comment_review_char</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>gross</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>made_up_column</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.002705</td>\n",
       "      <td>3.630552</td>\n",
       "      <td>2.683450</td>\n",
       "      <td>7.001743</td>\n",
       "      <td>6.583890</td>\n",
       "      <td>4.467420</td>\n",
       "      <td>4.647760</td>\n",
       "      <td>16.501699</td>\n",
       "      <td>10.096277</td>\n",
       "      <td>0.605564</td>\n",
       "      <td>4.871133</td>\n",
       "      <td>16.478166</td>\n",
       "      <td>1.845742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.053234</td>\n",
       "      <td>0.913946</td>\n",
       "      <td>0.218117</td>\n",
       "      <td>0.052173</td>\n",
       "      <td>0.944422</td>\n",
       "      <td>1.163810</td>\n",
       "      <td>0.242031</td>\n",
       "      <td>2.125449</td>\n",
       "      <td>1.990129</td>\n",
       "      <td>0.126912</td>\n",
       "      <td>1.392721</td>\n",
       "      <td>1.635744</td>\n",
       "      <td>0.210021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.907755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>5.087596</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-0.755015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.384495</td>\n",
       "      <td>0.470004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.957497</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>6.957497</td>\n",
       "      <td>6.236370</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>4.532599</td>\n",
       "      <td>15.950977</td>\n",
       "      <td>9.058761</td>\n",
       "      <td>0.564096</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>15.761421</td>\n",
       "      <td>1.757858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.003974</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>7.002156</td>\n",
       "      <td>6.869014</td>\n",
       "      <td>4.700480</td>\n",
       "      <td>4.634729</td>\n",
       "      <td>17.054875</td>\n",
       "      <td>10.444619</td>\n",
       "      <td>0.635025</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>16.811243</td>\n",
       "      <td>1.887070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.050123</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>7.046647</td>\n",
       "      <td>7.261225</td>\n",
       "      <td>5.267858</td>\n",
       "      <td>4.770685</td>\n",
       "      <td>17.754313</td>\n",
       "      <td>11.475317</td>\n",
       "      <td>0.680103</td>\n",
       "      <td>5.780744</td>\n",
       "      <td>17.504390</td>\n",
       "      <td>1.974081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.090077</td>\n",
       "      <td>4.595120</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>7.090077</td>\n",
       "      <td>7.549609</td>\n",
       "      <td>6.700731</td>\n",
       "      <td>6.236370</td>\n",
       "      <td>20.449494</td>\n",
       "      <td>14.340099</td>\n",
       "      <td>1.855818</td>\n",
       "      <td>8.529122</td>\n",
       "      <td>23.225971</td>\n",
       "      <td>6.396930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_market_idx  days_since_last_tweet  pre_screen_viewers  \\\n",
       "count       5043.000000            5043.000000         5043.000000   \n",
       "mean           7.002705               3.630552            2.683450   \n",
       "std            0.053234               0.913946            0.218117   \n",
       "min            6.907755               0.000000            2.302585   \n",
       "25%            6.957497               3.258097            2.484907   \n",
       "50%            7.003974               3.891820            2.708050   \n",
       "75%            7.050123               4.304065            2.890372   \n",
       "max            7.090077               4.595120            2.995732   \n",
       "\n",
       "       characters_per_longest_review  longest_facebook_comment_review_char  \\\n",
       "count                    5043.000000                           5043.000000   \n",
       "mean                        7.001743                              6.583890   \n",
       "std                         0.052173                              0.944422   \n",
       "min                         6.907755                              1.791759   \n",
       "25%                         6.957497                              6.236370   \n",
       "50%                         7.002156                              6.869014   \n",
       "75%                         7.046647                              7.261225   \n",
       "max                         7.090077                              7.549609   \n",
       "\n",
       "       num_critic_for_reviews     duration        gross  num_voted_users  \\\n",
       "count             5043.000000  5043.000000  5043.000000      5043.000000   \n",
       "mean                 4.467420     4.647760    16.501699        10.096277   \n",
       "std                  1.163810     0.242031     2.125449         1.990129   \n",
       "min                  0.000000     1.945910     5.087596         1.609438   \n",
       "25%                  3.912023     4.532599    15.950977         9.058761   \n",
       "50%                  4.700480     4.634729    17.054875        10.444619   \n",
       "75%                  5.267858     4.770685    17.754313        11.475317   \n",
       "max                  6.700731     6.236370    20.449494        14.340099   \n",
       "\n",
       "       made_up_column  num_user_for_reviews       budget   imdb_score  \n",
       "count     5043.000000           5043.000000  5043.000000  5043.000000  \n",
       "mean         0.605564              4.871133    16.478166     1.845742  \n",
       "std          0.126912              1.392721     1.635744     0.210021  \n",
       "min         -0.755015              0.000000     5.384495     0.470004  \n",
       "25%          0.564096              4.174387    15.761421     1.757858  \n",
       "50%          0.635025              5.049856    16.811243     1.887070  \n",
       "75%          0.680103              5.780744    17.504390     1.974081  \n",
       "max          1.855818              8.529122    23.225971     6.396930  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"ipynb_tmp\\profile_1302871085.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fa2e8a0080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Some of the columns have missing values. We can deal with this in a few different ways. The simpliest solution is to remove them, though we lose many examples in doing so. Alternatively, we could impute the values, replacing the NaN values with an average (mean or median). \n",
    "\n",
    "For the purpose of this simple notebook, the variable num_user_for_reviews has 51 zeros which was replaced by median and also remaining numerical variable are imputed by median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_median = df1[ df1.num_user_for_reviews != 0 ].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[ df1.num_user_for_reviews == 0, \"num_user_for_reviews\" ] = nonzero_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with median column values\n",
    "df1 = df1.fillna(df1.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5043 entries, 0 to 5042\n",
      "Data columns (total 13 columns):\n",
      "stock_market_idx                        5043 non-null float64\n",
      "days_since_last_tweet                   5043 non-null float64\n",
      "pre_screen_viewers                      5043 non-null float64\n",
      "characters_per_longest_review           5043 non-null float64\n",
      "longest_facebook_comment_review_char    5043 non-null float64\n",
      "num_critic_for_reviews                  5043 non-null float64\n",
      "duration                                5043 non-null float64\n",
      "gross                                   5043 non-null float64\n",
      "num_voted_users                         5043 non-null float64\n",
      "made_up_column                          5043 non-null float64\n",
      "num_user_for_reviews                    5043 non-null float64\n",
      "budget                                  5043 non-null float64\n",
      "imdb_score                              5043 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 551.6 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"using_parameteric_and_non_parametric_models\">\n",
    "     <h2>5. Data Modeling</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <li><b>5.1. Data Splitting</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test & Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of splitting the data is to be able to assess the quality of a predictive model when it is used on unseen data. When training, you will try to build a model that fits to the data as closely as possible, to be able to most accurately make a prediction. However, without a test set you run the risk of overfitting - the model works very well for the data it has seen but not for new data.\n",
    "\n",
    "The split ratio is often debated and in practice you might split your data into three sets: train, validation and test. You would use the training data to understand which classifier you wish to use; the validation set to test on whilst tweaking parameters; and the test set to get an understanding of how your final model would work in practice. Furthermore, there are techniques such as K-Fold cross validation that also help to reduce bias.\n",
    "\n",
    "For the purpose of this demonstration, we will only be randomly splitting our data into test and train, with a 80/20 split.\n",
    "\n",
    "We import the required library from scikit-learn, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.iloc[:,0:12].values\n",
    "y = df1.iloc[:,12:13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4034, 12)\n",
      "(4034, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainset.shape)\n",
    "print(y_trainset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009, 12)\n",
      "(1009, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_testset.shape)\n",
    "print(y_testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"using_parametric_and_non_parametric_models\">\n",
    "     <h2> Parametric Machine Learning Algorithm</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.2. Using Linear Regression</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression attempts to fit a straight hyperplane to your dataset that is closest to all data points. It is most suitable when there are linear relationships between the variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = reg.predict(X_testset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.2.1. Performance Metrics of Linear Regression</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to understand how good our model is; there are a few different metrics we can use. We will evaluate mean squared error (MSE) and mean absolute error (MAE)\n",
    "\n",
    "We import scikit-learn's mean squared error and sckit-learn's mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01813151995508253\n",
      "Mean Squared Error: 0.0014731432685910185\n",
      "Root Mean Squared Error: 0.03838154854342147\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_testset, y_pred1))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_testset, y_pred1))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_testset, y_pred1)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.3. Using Ridge Regression </b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.001, 0.01, 1, 5, 10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='mean_squared_error')\n",
    "\n",
    "ridge_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n",
      "-0.00248930108763342\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the optimal value for alpha is 1, and the negative MSE is -0.0024893."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.4. Using LASSO Regression </b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.0001, 0.001, 0.01, 1, 5, 10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='mean_squared_error')\n",
    "\n",
    "lasso_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n",
      "-0.0024895672740462694\n"
     ]
    }
   ],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the optimal value for alpha is 0.0001, and the negative MSE is -0.0024895.\n",
    "\n",
    "\n",
    "Note:\n",
    "After use linear, lasso, and ridge regression. We have seen that ridge is the best fitting method, with a regularization value of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"using_parameteric_and_non_parametric_models\">\n",
    "     <h2>Nonparametric ML Algorithms</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.5. Using KNRegressor </b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031100714262353453\n"
     ]
    }
   ],
   "source": [
    "clf=KNeighborsRegressor(5)\n",
    "clf.fit(X_trainset,y_trainset)\n",
    "y_pred=clf.predict(X_testset)\n",
    "print(mean_squared_error(y_testset,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 0.21315240080835277\n",
      "RMSE value for k=  2 is: 0.1908013268343305\n",
      "RMSE value for k=  3 is: 0.18098856364713534\n",
      "RMSE value for k=  4 is: 0.17803795746340828\n",
      "RMSE value for k=  5 is: 0.17635394597896994\n",
      "RMSE value for k=  6 is: 0.17416175135818351\n",
      "RMSE value for k=  7 is: 0.1731860406522612\n",
      "RMSE value for k=  8 is: 0.17230452241536612\n",
      "RMSE value for k=  9 is: 0.17302494104578212\n",
      "RMSE value for k=  10 is: 0.17256339138196394\n",
      "RMSE value for k=  11 is: 0.17266004948251795\n",
      "RMSE value for k=  12 is: 0.1728858069932387\n",
      "RMSE value for k=  13 is: 0.17274587714990983\n",
      "RMSE value for k=  14 is: 0.1730896798547398\n",
      "RMSE value for k=  15 is: 0.17308010745515268\n",
      "RMSE value for k=  16 is: 0.1730563602443598\n",
      "RMSE value for k=  17 is: 0.17335005398973438\n",
      "RMSE value for k=  18 is: 0.17323566744883404\n",
      "RMSE value for k=  19 is: 0.1736963168112529\n",
      "RMSE value for k=  20 is: 0.17340505276908819\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(X_trainset, y_trainset)  #fit the model\n",
    "    pred=model.predict(X_testset) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_testset,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa2e148588>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val) #elbow curve \n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with other Number of clusters, k=8 and RMSE is 0.172 is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>5.6. Using of Random Forest</b></li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)  \n",
    "regressor.fit(X_trainset, y_trainset)  \n",
    "y_pred = regressor.predict(X_testset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.00044979607149377013\n",
      "Mean Squared Error: 4.4625280188515924e-05\n",
      "Root Mean Squared Error: 0.006680215579494117\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_testset, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_testset, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_testset, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When estimator is 20 then RMSE is 0.007 and MSE is 4.46."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "After comparing non-parametric models RMSE, Random forest performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used backward selection method for multiple regression to find better R-square and all p-value of variable should be significantly significant (less than 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     7691.\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:39:57   Log-Likelihood:                 8184.7\n",
      "No. Observations:                5043   AIC:                        -1.634e+04\n",
      "Df Residuals:                    5030   BIC:                        -1.626e+04\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0315      0.129      7.993      0.000       0.778       1.284\n",
      "x1            -0.0032      0.001     -6.456      0.000      -0.004      -0.002\n",
      "x2            -0.0086      0.013     -0.678      0.498      -0.033       0.016\n",
      "x3            -0.0001      0.001     -0.139      0.890      -0.002       0.001\n",
      "x4            -0.0003      0.003     -0.106      0.915      -0.006       0.006\n",
      "x5            -0.0137      0.013     -1.059      0.290      -0.039       0.012\n",
      "x6            -0.0008      0.001     -1.065      0.287      -0.002       0.001\n",
      "x7            -0.0059      0.001     -5.906      0.000      -0.008      -0.004\n",
      "x8             0.0068      0.003      2.282      0.023       0.001       0.013\n",
      "x9         -5.332e-05      0.000     -0.143      0.886      -0.001       0.001\n",
      "x10            0.0041      0.001      5.531      0.000       0.003       0.006\n",
      "x11            1.5940      0.006    279.342      0.000       1.583       1.605\n",
      "x12            0.0037      0.001      3.635      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13727.176   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        583187610.018\n",
      "Skew:                          33.242   Prob(JB):                         0.00\n",
      "Kurtosis:                    1667.636   Cond. No.                     5.72e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.72e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], df1['stock_market_idx'], df1['days_since_last_tweet'], df1['pre_screen_viewers'],\n",
    "                     df1['characters_per_longest_review'], df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df1['gross'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['pre_screen_viewers']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     8391.\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:39:59   Log-Likelihood:                 8184.7\n",
      "No. Observations:                5043   AIC:                        -1.635e+04\n",
      "Df Residuals:                    5031   BIC:                        -1.627e+04\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0307      0.129      8.001      0.000       0.778       1.283\n",
      "x1            -0.0032      0.001     -6.456      0.000      -0.004      -0.002\n",
      "x2            -0.0086      0.013     -0.678      0.498      -0.033       0.016\n",
      "x3            -0.0001      0.001     -0.140      0.889      -0.002       0.001\n",
      "x4            -0.0137      0.013     -1.060      0.289      -0.039       0.012\n",
      "x5            -0.0008      0.001     -1.066      0.287      -0.002       0.001\n",
      "x6            -0.0059      0.001     -5.906      0.000      -0.008      -0.004\n",
      "x7             0.0068      0.003      2.282      0.023       0.001       0.013\n",
      "x8          -5.33e-05      0.000     -0.143      0.886      -0.001       0.001\n",
      "x9             0.0041      0.001      5.533      0.000       0.003       0.006\n",
      "x10            1.5940      0.006    279.385      0.000       1.583       1.605\n",
      "x11            0.0037      0.001      3.634      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13727.412   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        583262636.992\n",
      "Skew:                          33.244   Prob(JB):                         0.00\n",
      "Kurtosis:                    1667.743   Cond. No.                     5.69e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.69e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], df1['stock_market_idx'], df1['days_since_last_tweet'], \n",
    "                     df1['characters_per_longest_review'], df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df1['gross'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['gross']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     9232.\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:00   Log-Likelihood:                 8184.7\n",
      "No. Observations:                5043   AIC:                        -1.635e+04\n",
      "Df Residuals:                    5032   BIC:                        -1.628e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0306      0.129      8.002      0.000       0.778       1.283\n",
      "x1            -0.0033      0.000     -6.673      0.000      -0.004      -0.002\n",
      "x2            -0.0086      0.013     -0.681      0.496      -0.033       0.016\n",
      "x3            -0.0001      0.001     -0.138      0.890      -0.002       0.001\n",
      "x4            -0.0137      0.013     -1.063      0.288      -0.039       0.012\n",
      "x5            -0.0008      0.001     -1.067      0.286      -0.002       0.001\n",
      "x6            -0.0058      0.001     -5.953      0.000      -0.008      -0.004\n",
      "x7             0.0069      0.003      2.291      0.022       0.001       0.013\n",
      "x8             0.0041      0.001      5.572      0.000       0.003       0.006\n",
      "x9             1.5940      0.006    280.066      0.000       1.583       1.605\n",
      "x10            0.0037      0.001      3.667      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13726.670   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        582997176.363\n",
      "Skew:                          33.239   Prob(JB):                         0.00\n",
      "Kurtosis:                    1667.364   Cond. No.                     4.71e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.71e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], df1['stock_market_idx'], df1['days_since_last_tweet'], \n",
    "                     df1['characters_per_longest_review'], df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['days_since_last_tweet']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.949\n",
      "Model:                            OLS   Adj. R-squared:                  0.949\n",
      "Method:                 Least Squares   F-statistic:                 1.043e+04\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:01   Log-Likelihood:                 8223.5\n",
      "No. Observations:                5043   AIC:                        -1.643e+04\n",
      "Df Residuals:                    5033   BIC:                        -1.636e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0974      0.128      8.583      0.000       0.847       1.348\n",
      "x1            -0.0028      0.000     -6.085      0.000      -0.004      -0.002\n",
      "x2            -0.0113      0.013     -0.897      0.370      -0.036       0.013\n",
      "x3            -0.0151      0.013     -1.177      0.239      -0.040       0.010\n",
      "x4            -0.0007      0.001     -1.023      0.307      -0.002       0.001\n",
      "x5            -0.0035      0.001     -4.009      0.000      -0.005      -0.002\n",
      "x6             0.0036      0.003      1.209      0.227      -0.002       0.009\n",
      "x7           6.57e-08   6.27e-09     10.472      0.000    5.34e-08     7.8e-08\n",
      "x8             1.5878      0.006    279.653      0.000       1.577       1.599\n",
      "x9             0.0033      0.001      3.751      0.000       0.002       0.005\n",
      "==============================================================================\n",
      "Omnibus:                    13897.771   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        640334751.739\n",
      "Skew:                          34.339   Prob(JB):                         0.00\n",
      "Kurtosis:                    1747.329   Cond. No.                     3.11e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.11e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], df1['stock_market_idx'], \n",
    "                     df1['characters_per_longest_review'], df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['stock_market_idx']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                 1.154e+04\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:01   Log-Likelihood:                 8184.5\n",
      "No. Observations:                5043   AIC:                        -1.635e+04\n",
      "Df Residuals:                    5034   BIC:                        -1.629e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9687      0.091     10.589      0.000       0.789       1.148\n",
      "x1            -0.0033      0.000     -6.688      0.000      -0.004      -0.002\n",
      "x2            -0.0136      0.013     -1.049      0.294      -0.039       0.012\n",
      "x3            -0.0008      0.001     -1.076      0.282      -0.002       0.001\n",
      "x4            -0.0059      0.001     -5.975      0.000      -0.008      -0.004\n",
      "x5             0.0068      0.003      2.284      0.022       0.001       0.013\n",
      "x6             0.0041      0.001      5.605      0.000       0.003       0.006\n",
      "x7             1.5940      0.006    280.140      0.000       1.583       1.605\n",
      "x8             0.0037      0.001      3.668      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13728.449   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        583620066.860\n",
      "Skew:                          33.250   Prob(JB):                         0.00\n",
      "Kurtosis:                    1668.253   Cond. No.                     3.18e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.18e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], \n",
    "                     df1['characters_per_longest_review'], df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['characters_per_longest_review']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                 1.319e+04\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:02   Log-Likelihood:                 8183.9\n",
      "No. Observations:                5043   AIC:                        -1.635e+04\n",
      "Df Residuals:                    5035   BIC:                        -1.630e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8740      0.015     59.630      0.000       0.845       0.903\n",
      "x1            -0.0032      0.000     -6.657      0.000      -0.004      -0.002\n",
      "x2            -0.0008      0.001     -1.110      0.267      -0.002       0.001\n",
      "x3            -0.0058      0.001     -5.962      0.000      -0.008      -0.004\n",
      "x4             0.0068      0.003      2.268      0.023       0.001       0.013\n",
      "x5             0.0041      0.001      5.598      0.000       0.003       0.006\n",
      "x6             1.5938      0.006    280.199      0.000       1.583       1.605\n",
      "x7             0.0037      0.001      3.666      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13731.611   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        584547592.701\n",
      "Skew:                          33.270   Prob(JB):                         0.00\n",
      "Kurtosis:                    1669.576   Cond. No.                         489.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], \n",
    "                     df1['longest_facebook_comment_review_char'], \n",
    "                     df1['num_critic_for_reviews'], df1['duration'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['longest_facebook_comment_review_char']\n",
    "df1.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             imdb_score   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                 1.539e+04\n",
      "Date:                Sat, 20 Jul 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:40:04   Log-Likelihood:                 8183.3\n",
      "No. Observations:                5043   AIC:                        -1.635e+04\n",
      "Df Residuals:                    5036   BIC:                        -1.631e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8689      0.014     62.356      0.000       0.842       0.896\n",
      "x1            -0.0032      0.000     -6.660      0.000      -0.004      -0.002\n",
      "x2            -0.0058      0.001     -5.964      0.000      -0.008      -0.004\n",
      "x3             0.0068      0.003      2.263      0.024       0.001       0.013\n",
      "x4             0.0042      0.001      5.614      0.000       0.003       0.006\n",
      "x5             1.5937      0.006    280.208      0.000       1.583       1.605\n",
      "x6             0.0036      0.001      3.643      0.000       0.002       0.006\n",
      "==============================================================================\n",
      "Omnibus:                    13733.185   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        585152979.355\n",
      "Skew:                          33.280   Prob(JB):                         0.00\n",
      "Kurtosis:                    1670.440   Cond. No.                         445.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((df1['budget'], df1['num_critic_for_reviews'], df1['duration'], df1['num_voted_users'], \n",
    "                     df1['made_up_column'], df1['num_user_for_reviews']))\n",
    "y = df1['imdb_score']\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The target variable or dependent variable and independent variables were continuous. I used lof transformation to normalize the variables.\n",
    "After verifing Linear Regression assumptions, I move forward with predictive modeling and got adjusted R-square of 95%.\n",
    "After using backward selection technique, the remaining independent variables p-value is < 0.05 which shows that variables are significant. \n",
    "RMSE is also less which is 0.04."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After checking RMSE of the other algorithm, Random Forset root mean squared error is less which is 0.007. It shows that random forset perform better comparing with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Modules\">\n",
    "     <h2> Modules</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"df2\">\n",
    "     <h2>Creating new dataframe as df2</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"clean_and_transform\">\n",
    "    <h2> Clean & Transform</h2>\n",
    "    The target variable is numeric and have duplicates. My goal is to build a model, which can help us predict if a movie is good or bad.So, I cleaned it and transformed it into levels: 1 means movie was good and 0 means movie was bad.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data clean up/ transformation\n",
    "# 1 = Good and 0 = when Bad\n",
    "df2.loc[df.imdb_score < 8.0, 'imdb_score'] = 0\n",
    "df2.loc[df.imdb_score >= 8.0, 'imdb_score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.imdb_score.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imdb_score is dichotomous now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables\n",
    "df2 = pd.get_dummies(df2, columns = ['color', 'director_name',\n",
    "       'actor_2_name', 'genres', 'actor_1_name', 'movie_title', 'actor_3_name',\n",
    "       'plot_keywords', 'language', 'country', 'content_rating'], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Some of the columns have missing values. We can deal with this in a few different ways. The simpliest solution is to remove them, though we lose many examples in doing so. Alternatively, we could impute the values, replacing the NaN values with an average (mean or median). For the purpose of this simple notebook, we will simply remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "df2 = df2.drop(columns=['cast_total_facebook_likes', 'made_up_column', 'priority', 'website_score','weighted_budget',\n",
    "                      'movie_imdb_link']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5043, 21780)\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true,y_pred):\n",
    "    print(precision_recall_fscore_support(y_true, y_pred,average='macro'))\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred,labels=[1,0]))\n",
    "\n",
    "#df = pd.read_excel(\"../data/dataset_exercise.xlsx\",header=0)\n",
    "#df = df.drop(\"id\",axis=1)\n",
    "target = df2[\"imdb_score\"]\n",
    "df2_x = df2.drop(\"imdb_score\",axis=1)\n",
    "\n",
    "df2_x = df2_x.dropna(thresh=int(len(df2_x)*0.5), axis=1)\n",
    "print(df2_x.shape)\n",
    "df2_x = df2_x.fillna(df2_x.mean())\n",
    "\n",
    "x = df2_x.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# stand = preprocessing.StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df2_x_pre = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(df2_x_pre,target)\n",
    "df2scores = pd.DataFrame(fit.scores_)\n",
    "df2columns = pd.DataFrame(df2_x_pre.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([df2columns,df2scores],axis=1)\n",
    "df2_x_backup = df2_x_pre.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5043, 21745)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_x_pre = df2_x_backup.copy()\n",
    "# df_new = \n",
    "conf_sum = 0 \n",
    "index = 0\n",
    "for i in df2scores.values:\n",
    "    if i[0]<0.05:\n",
    "        conf_sum+=i[0]\n",
    "        df2_x_pre = df2_x_pre.drop(df2_x_pre.columns[index], axis=1)\n",
    "        index-=1\n",
    "    index+=1\n",
    "    \n",
    "df2_x_pre.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"splitting_data\">\n",
    "     <h2>2. Split Data on df2 dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4034, 21745)\n",
      "(1009, 21745)\n",
      "(4034,)\n",
      "(1009,)\n",
      "testing data=\n",
      "1= 72.0\n",
      "0= 937.0\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df2_x_pre, target, test_size=0.20, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"testing data=\")\n",
    "print(\"1=\",np.sum(y_test))\n",
    "print(\"0=\",len(y_test)-np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"LogisticRegression\">\n",
    "     <h2> Logistic Regression</h2> (Parametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8927698032961191, 0.6095102573224238, 0.6605154057151981, None)\n",
      "0.9415262636273538\n",
      "[[ 16  56]\n",
      " [  3 934]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression(random_state=0, solver='lbfgs').fit(x_train, y_train)\n",
    "y_pred= clf1.predict(x_test)\n",
    "\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of Logistic Regression </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97       937\n",
      "        1.0       0.84      0.22      0.35        72\n",
      "\n",
      "avg / total       0.94      0.94      0.93      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = clf1.predict(x_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415262636273538"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"KNN\">\n",
    "     <h2> K Nearest Neighbor</h2> (Nonparametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7628676470588236, 0.5657091189375074, 0.594474636098345, None)\n",
      "0.931615460852329\n",
      "[[ 10  62]\n",
      " [  7 930]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3).fit(x_train, y_train)\n",
    "y_pred= clf2.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of KNN </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96       937\n",
      "        1.0       0.59      0.14      0.22        72\n",
      "\n",
      "avg / total       0.91      0.93      0.91      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict2 = clf2.predict(x_test)\n",
    "print(classification_report(y_test,predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931615460852329"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"gaussian_process\">\n",
    "     <h2> Gaussian Process Classifier</h2> (Nonparametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9652432969215492, 0.5138888888888888, 0.5090229118006895, None)\n",
      "0.9306243805748265\n",
      "[[  2  70]\n",
      " [  0 937]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "clf3 = GaussianProcessClassifier(random_state=0).fit(x_train, y_train)\n",
    "y_pred= clf3.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of Gaussian </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96       937\n",
      "        1.0       1.00      0.03      0.05        72\n",
      "\n",
      "avg / total       0.94      0.93      0.90      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict3 = clf3.predict(x_test)\n",
    "print(classification_report(y_test,predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306243805748265"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Navie_Bayes\">\n",
    "     <h2> Multinominal Naive Bayes</h2> (Parametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4643211100099108, 0.5, 0.4815005138746146, None)\n",
      "0.9286422200198216\n",
      "[[  0  72]\n",
      " [  0 937]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf4 = MultinomialNB().fit(x_train, y_train)\n",
    "y_pred= clf4.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of MNB </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96       937\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "\n",
      "avg / total       0.86      0.93      0.89      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict4 = clf4.predict(x_test)\n",
    "print(classification_report(y_test,predict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286422200198216"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Decision_tree\">\n",
    "     <h2> Decision Tree</h2> (Nonparametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7666868015705225, 0.7355923159018143, 0.7499380421313506, None)\n",
      "0.9375619425173439\n",
      "[[ 36  36]\n",
      " [ 27 910]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf5 = tree.DecisionTreeClassifier().fit(x_train, y_train)\n",
    "y_pred= clf5.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of Decision Tree </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.97      0.97       937\n",
      "        1.0       0.57      0.50      0.53        72\n",
      "\n",
      "avg / total       0.93      0.94      0.94      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict5 = clf5.predict(x_test)\n",
    "print(classification_report(y_test,predict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375619425173439"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Random_Forest\">\n",
    "     <h2> Random_Forest</h2> (Nonparametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9703815261044177, 0.5902777777777778, 0.6376799245305985, None)\n",
      "0.9415262636273538\n",
      "[[ 13  59]\n",
      " [  0 937]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf6 = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0).fit(x_train, y_train)\n",
    "y_pred= clf6.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of Random Forest </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97       937\n",
      "        1.0       1.00      0.18      0.31        72\n",
      "\n",
      "avg / total       0.94      0.94      0.92      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict6 = clf6.predict(x_test)\n",
    "print(classification_report(y_test,predict6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415262636273538"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"GradientBoosting\">\n",
    "     <h2> Gradient Boosting</h2> (Nonparametric Model)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6842335224688165, 0.728129076248073, 0.7030046467018339, None)\n",
      "0.9117938553022795\n",
      "[[ 37  35]\n",
      " [ 54 883]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf7 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(x_train, y_train)\n",
    "y_pred= clf7.predict(x_test)\n",
    "calculate_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Performance_Matrix\">\n",
    "     <h2> Performance Matrix of GB </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.94      0.95       937\n",
      "        1.0       0.41      0.51      0.45        72\n",
      "\n",
      "avg / total       0.92      0.91      0.92      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict7 = clf7.predict(x_test)\n",
    "print(classification_report(y_test,predict7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117938553022795"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predict7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: After seeing confusion matrix of parametric model, I found that Logistic Regression performed better where accuray is 94% and F1-score is 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing confusion matrix of nonparametric model, I found that Random Forest performed better where accuracy was 94% and F1-score is 0.92."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"recommendations\">\n",
    "    <h2>Recommendation</h2>\n",
    "    Findings \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Based on continuous dependent and independent variable, random forest (Regressor) performed better.\n",
    "\n",
    "2. After leveling the continuous dependent variable and creating dummies of independent variables, random forest performed better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
